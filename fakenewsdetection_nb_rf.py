# -*- coding: utf-8 -*-
"""FakeNewsDetection_NB_RF

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Y5ayJdqD1DgvCJGA99iALU4G5PWrOvcJ

# Fake News Detection

<!-- # EDA -->
<div id = "eda" style = "height: 50px;
  width: 800px;
  background-color: #813EEC;">
    <h1 style="padding: 10px;
              color:white;">
        <b>1.EDA</b>
    </h1>

</div>
"""

#importing Libraries
import numpy as np
import pandas as pd
from matplotlib.pylab import plt
import seaborn as sns
from sklearn import metrics
from sklearn.metrics import confusion_matrix , classification_report
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from wordcloud import WordCloud
import re
from nltk.corpus import stopwords
from nltk.stem.porter import PorterStemmer
import nltk

"""#        1.1 Reading Data
   
"""

df = pd.read_csv('/kaggle/input/fake-news-classification/WELFake_Dataset.csv')
df.head(120)

df.describe()

df.info()

y = df.label
print(f'Ratio of real and fake news:')
y.value_counts(normalize=True).rename({1: 'real', 0: 'fake'})

df.drop(["Unnamed: 0"], axis=1, inplace=True)

df.isnull().sum().plot(kind="barh")
plt.show()

"""# Observations:

         There are a total of 4 columns and 72134 rows in the data
         Label is the target variable
         Percentage of Real and fake News articles:
         real : 51%
         fake :49%
         Missing values are present in the dataset
   
"""

df.isnull().sum()

df = df.fillna('')

df.isnull().sum()

df.nunique()

df["title_text"] = df["title"] + df["text"]
df["body_len"] = df["title_text"].apply(lambda x: len(x) - x.count(" "))
df.head(50)

bins = np.linspace(0, 4000, 40)

plt.hist(df[df["label"]== 1]["body_len"], bins, alpha=0.5, label="Fake", color="red")
plt.hist(df[df["label"]== 0]["body_len"], bins, alpha=0.5, label="Real", color="blue")
plt.legend(loc="upper left")
plt.show()

"""# Insights :
       
 Fake news seem to be quite a bit longer than real news.
"""

# Assuming df is your DataFrame and it has a 'label' column
class_names = ['Fake', 'Real']
label_count = df['label'].value_counts()

# Create the barplot with a custom color palette
sns.barplot(x=label_count.index, y=label_count, palette=['gray', 'green'])

# Set the title and other plot properties
plt.title('Distribution of Fake/Real News', fontsize=14)
plt.xlabel('News Type')
plt.ylabel('Count')
plt.xticks(ticks=[0, 1], labels=class_names)  # Ensure the x-axis labels are shown as 'fake' and 'real'

# Display the plot
plt.show()

y.head()

X_train, X_test, y_train, y_test = train_test_split(df['text'], y, test_size=0.33, random_state=53)

print(X_train.shape)
print(X_test.shape)
print(y_train.shape)
print(y_test.shape)
print(type(X_train))
print(X_train)

"""# Data Visualization of all News Titles
   
"""

titles = ' '.join(title for title in df['title'])
wordcloud = WordCloud(
    background_color='white',
    max_words=300,
    width=800,
    height=400,
).generate(titles)

plt.figure(figsize=(20, 10))
plt.imshow(wordcloud, interpolation='bilinear')
plt.axis("off")
plt.show()

"""# Quick Insights:
        
many of available news articles are about elections and presidents of USA

#       1.3 Data Visualization of texts in fake news
"""

fake_news = X_train[y_train == 0]
real_news = X_train[y_train == 1]
fake_texts = ' '.join(text for text in fake_news)
wordcloud = WordCloud(
    background_color='white',
    max_words=300,
    width=800,
    height=400,
).generate(fake_texts)

plt.figure(figsize=(20, 10))
plt.imshow(wordcloud, interpolation='bilinear')
plt.axis("off")
plt.show()

"""#       1.4 Data Visualization of texts in Real news
  
"""

real_texts = ' '.join(text for text in real_news)
wordcloud = WordCloud(
    background_color='white',
    max_words=300,
    width=800,
    height=400,
).generate(real_texts)

plt.figure(figsize=(20, 10))
plt.imshow(wordcloud, interpolation='bilinear')
plt.axis("off")
plt.show

"""# 2.Bag of Words Model"""

count_vectorizer = CountVectorizer(stop_words='english')
count_train = count_vectorizer.fit_transform(X_train)
count_test = count_vectorizer.transform(X_test)

print(count_train.shape)
print(y_train.shape)

"""# 3.Training Naive Bayes Model</b>

"""

from sklearn.naive_bayes import MultinomialNB
nb_classifier = MultinomialNB()
nb_classifier.fit(count_train, y_train)

"""#       3.1 Predictions on NB model

"""

pred = nb_classifier.predict(count_test)

"""#       3.2 Evaluation of NB predictions

"""

print(classification_report(y_test, pred))

"""# Accuracy achieved using Naive Bayes Model : 89%

#       3.3 Confusion Matrix
"""

plt.figure(figsize = (8,6))

sns.heatmap(confusion_matrix(y_test,pred), annot=True,
            fmt='', cmap='Greens')

plt.xlabel('Predicted Labels')
plt.ylabel('Real Labels')

"""# 4.Training Random Forest Model"""

from sklearn.ensemble import RandomForestClassifier
model = RandomForestClassifier(n_estimators=300)
model.fit(count_train, y_train)

"""#       4.1 Predictions on Random Forest Classifier
    
"""

pred2 = model.predict(count_test)

"""#       4.2 Evaluation of RF Classifier Predictions
    
"""

print(classification_report(y_test, pred2,digits=4))

"""# Accuracy achieved using Random Forest Model : 94%

#       4.3 Confusion Matrix
"""

plt.figure(figsize = (8,6))

sns.heatmap(confusion_matrix(y_test,pred2), annot=True,
            fmt='', cmap='Greens')

plt.xlabel('Predicted Labels')
plt.ylabel('Real Labels')